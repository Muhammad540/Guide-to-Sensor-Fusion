{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filtering: How and Why it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases for Particle Filter\n",
    "\n",
    "1. Multi-modal problems: Tracking multiple vehicles on a highway using radar data. Each vehicle represents a different mode in the state distribution, and the particle filter can handle the multiple hypotheses effectively.\n",
    "\n",
    "2. Occluded Objects : In computer vision, a pedestrian walking behind a parked car becomes temporarily hidden from a camera's view. A particle filter can predict the pedestrian's position during occlusion by maintaining multiple possible states.\n",
    "\n",
    "3. Systems with non-linear behavior : An aircraft navigating through turbulent weather where wind forces cause non-linear effects on its trajectory. Another example is a robot arm with joint friction and backlash, leading to non-linear motion dynamics.\n",
    "\n",
    "4. Systems providing non-linear measurements : A robot using a laser rangefinder measures distances to obstacles. Converting these measurements to Cartesian coordinates involves trigonometric functions, introducing non-linearity.\n",
    "\n",
    "5. System with non-gaussian noise : A sensor affected by electromagnetic interference, causing occasional large errors (outliers) in measurements. The noise distribution might be heavy-tailed (e.g., a Cauchy distribution) rather than Gaussian.\n",
    "\n",
    "6. System variables changing continiously : the object's position and velocity can smoothly change over time.\n",
    "\n",
    "7. multivariate problem: we want to track several attributes, such as position, velocity, turn rates, etc.\n",
    "\n",
    "8. Unknown system model : we may not know the process model of the system.\n",
    "\n",
    "#### None of the following filters will work well with all of the above constraints:\n",
    "\n",
    "1. Discrete Bayes Fitler : Suitable for discrete state spaces but not efficient for continuous or high-dimensional problems.\n",
    "\n",
    "2. Kalman Filter : Assumes linear system models and Gaussian noise, which limits its applicability to non-linear or non-Gaussian systems.\n",
    "\n",
    "3. Unscented kalman Filter: Linearizes non-linear models around the current estimate, which can introduce significant errors if the system is highly non-linear.\n",
    "\n",
    "4. Extended Kalman Filter : Handles non-linearities better than EKF but still assumes Gaussian noise and may not perform well with multi-modal distributions or non-Gaussian noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it ? Tell me in Simple words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In very simple words, Let us take a robot localization problem you will take a finite number of particles and sprinkle them in the environment around your robot which you want to track. Then using prediction, update and resampling steps you get a nice estimate of your robots location.\n",
    "\n",
    "*side note: Sampling simply means generating a set of random possible states (x,y,z, oritentation) of the robot from a probability distribution. It can be any sort of distribution !*\n",
    "\n",
    "There are three main steps that you need to keep in mind: \n",
    "\n",
    "1. Predict \n",
    "2. Update \n",
    "3. Resample\n",
    "\n",
    "And particle filter algorithm will just run an iterative prediction-correction-Resample loop. The good thing is that it can estimate the states despite the process and measurement noise, which can be of any arbitrary non-gaussain distribution. Process noise is simply the uncertainty in how the system's state changes over time due to unpredictable influences or model inaccuracies while Measurement noise is uncertainty in the observations caused by sensor errors/noise.\n",
    "\n",
    "Below you can view how a generic particle filter algorithm is structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display, Image\n",
    "\n",
    "img = plt.imread(\"flowchart.png\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Flow chart representing a generic Particle filter algorithm\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss the basic particle filter algorithm for the robot localization problem. We have a robot whose orientation and velocity can be controlled by the user. It also has sensors that measure distances to obstacles. Both the sensors and the control mechanisms have noise, and our goal is to track the robot's position despite this uncertainty.\n",
    "\n",
    "##### Before going any further, let's clarify what particles are:\n",
    "\n",
    "* Particles: A particle is a simulated possible position and orientation of the robot. Each particle represents a belief about where the robot could be located. So, each particle has a position (x, y) and an orientation angle. Additionally, particles have an associated weight. You can think of all of the particles representing a probability distribution, locations where there are more particles represent a higher belief(that robot is at the position), and locations with fewer particles represents a lower belief(robot is likely not there). If there was a large clump of particles near a specific location that would imply that we are more certain that the robot is there.\n",
    "\n",
    "* Weight: The weight indicates how likely it is that the particle represents the robot's true state. A higher weight means the particle more closely matches the robot's actual position.\n",
    "\n",
    "##### Now, let's go through the steps of the particle filter algorithm:\n",
    "\n",
    "*1. Randomly Generate Particles:* We start by randomly placing particles around an initial guessed position of the robot. If no guess is available, we can spread the particles uniformly across the entire map. Each particle is initialized with the same weight and has a certain (x,y) position and orientation.\n",
    "\n",
    "*2. Predict the Next State of the Particles:* As the robot moves, we update all the particles based on the robot's control inputs and a motion model that includes some randomness to account for movement noise. For example, if the robot moves 1 meter forward and rotates 20 degrees, we move each particle accordingly but also add slight variations to simulate the uncertainty in motion.\n",
    "\n",
    "*3. Update Weights:* We update the weights of all particles by comparing their predicted sensor readings to the actual sensor data received (e.g., from a 2D lidar). Particles whose predicted measurements closely match the actual sensor data receive higher weights, indicating they are more likely to represent the robot's true state.\n",
    "\n",
    "*4. Resample:* We remove particles with low weights and replace them with new particles sampled from those with higher weights. This step concentrates the particles around the more probable (higher weight) states.\n",
    "\n",
    "*5. Compute Estimate:* To estimate the robot's current position, we compute the weighted average of the particles' positions and orientations.\n",
    "\n",
    "We repeat these steps multiple times. As the algorithm iterates, the particles converge around the robot's true position. This allows us to accurately track the robot's movement despite the noise in sensors and control inputs. Observe the gif below :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML('<a href=\"https://drive.google.com/file/d/18LyPVCw7A8dPH7s46XfZRgiz9-doLP_u/view?usp=sharing\" target=\"_blank\">Figure 2: Animation of generic particle filter algorithm</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go over the important steps in bit of a detail:\n",
    "\n",
    "### Predict Step Exaplained \n",
    "\n",
    "In the predict step of the particle filter, each particle represents a possible position and orientation of the robot. Lets think about it, when we send a command to the robot—for example, to move forward by 0.1 meters and turn by 0.007 radians— we can also move all the particles exactly these amounts (wherever they might be). However, this would cause a problem because the robot's movements are not perfect (remember noise in control system of robot); it won't move exactly as commanded due to control noise and uncertainties.\n",
    "\n",
    "To address this, we add randomness (noise) to the movement of each particle. Instead of moving each particle exactly by the commanded amounts, we add some noise to the command and move the particle with that modified command. This means each particle moves slightly differently, simulating the imperfections in the robot's actual movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    modified command = noise + user command "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modeling the uncertainty in the robot's motion, the particle filter accurately captures the range of possible positions the robot could be in. This ensures that the filter correctly represents our belief about the robot's position as a probability distribution, accounting for the inherent noise in the control system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('predict_step_dispersion.png')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Figure 3: During the predict step, particles are propagated forward by adding\\nsome noise to user command according to odometry motion model.\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Step Explained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the update step of the particle filter algorithm, it's important to understand the concept of likelihood. Likelihood is a key idea in Bayes' theorem, and since the particle filter is based on Bayesian principles, grasping this concept is essential. \n",
    "\n",
    "Think of likelihood as a score that indicates how likely it is for something to happen, given some evidence.\n",
    "\n",
    "#### So taking the robot localization problem, \n",
    "\n",
    "##### *Particles as Hypotheses:* \n",
    "\n",
    "Each particle represents a possible position and orientation of the robot—a hypothesis about where the robot might be.\n",
    "\n",
    "##### *Calculating Likelihood:*\n",
    "\n",
    "We compare the expected 2D sensor readings if the sensor was located at each of the particle's position to the actual sensor readings the robot receives. If a particle's expected readings closely match the actual readings, the likelihood for that particle is high. \n",
    "\n",
    "Example: Assume a particle A at x=1,y=1. Robot with sensor is at x=0, y=0. We would compute the sensor reading if the sensor was at the particle's position (x=1, y=1) and then compare by taking a difference of that sensor reading with the actual sensor reading at x=0,y=0 which is the true sensor reading. We do this for all the particles and proportional to that difference we assign a weight. \n",
    "\n",
    "##### *Updating Weights:*\n",
    "\n",
    "The likelihood determines the weight of each particle. Particles with higher likelihoods (better matches to the observed/true data) receive higher weights.\n",
    "\n",
    "In short these are the sub-steps in this Update Step: \n",
    "1. Process incoming sensor measurements\n",
    "2. Compare them with simulated measurments of the particles on the map\n",
    "3. Prioritize particles where measurements and map have the lowest error\n",
    "\n",
    "##### Follow the images below:\n",
    "\n",
    "Step 1: Robot observes the environment by acquiring distances from the range sensor position toward nearby obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('laser_scans_real_robot.png')\n",
    "plt.imshow(image)\n",
    "plt.title('Starting Robot position with the area captured by laser scan')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: The filter simulates for each particle a laser scan by raycasting against the internal map at each particle's pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = mpimg.imread('p1.png')\n",
    "image2 = mpimg.imread('p2.png')\n",
    "image3 = mpimg.imread('p3.png')\n",
    "image4 = mpimg.imread('p4.png')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "axes[0].imshow(image1)\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(image2)\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(image3)\n",
    "axes[2].axis('off')\n",
    "axes[3].imshow(image4)\n",
    "axes[3].axis('off')\n",
    "fig.suptitle('Raytracing for each particle: the region of scan area it captures', fontsize=14)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: The degree of matching between distances obtained by the real laser scan and the distances calculated by each particle's expected distance measurement determines the likelihood of a particle being in the vicinity of the robot's ground truth pose. During this process, a new weight is assigned\n",
    "to each particle corresponding to how close the each particles predicted scan is to the real robot laser scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('scan_matching.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image)\n",
    "plt.title('Scan Matching')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particles with the highest weight are used to estimate the position of the robot. Particles with small weights are discarded.\n",
    "\n",
    "Notice how the amount of unique structural features in the environment is important: the more, the better. If the environment is ambiguous, for example, with large empty walls, with no edges, with no windows, no doors, or other features that can provide relevant information for the robot to determine its pose, the particle filter will not perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the State Estimate\n",
    "\n",
    "To estimate the robot's position after each update step we can compute the mean of the estimate as the sum of the weighted values of the particles. \n",
    "\n",
    "$$\\displaystyle \\mu = \\frac{1}{N}\\sum_{i=1}^N w^ix^i$$\n",
    "\n",
    "Let's give an example:\n",
    "\n",
    "Suppose we have three particles:\n",
    "\n",
    "- **Particle 1**:\n",
    "  - Position: \\( x^1 = (2, 3) \\)\n",
    "  - Weight: \\( w^1 = 0.2 \\)\n",
    "\n",
    "- **Particle 2**:\n",
    "  - Position: \\( x^2 = (4, 5) \\)\n",
    "  - Weight: \\( w^2 = 0.5 \\)\n",
    "\n",
    "- **Particle 3**:\n",
    "  - Position: \\( x^3 = (3, 4) \\)\n",
    "  - Weight: \\( w^3 = 0.3 \\)\n",
    "\n",
    "Compute the estimated position:\n",
    "\n",
    "For the x-coordinate:\n",
    "\n",
    "$$\n",
    "\\mu_x = w^1 x^1_x + w^2 x^2_x + w^3 x^3_x \\\\\n",
    "\\mu_x = (0.2)(2) + (0.5)(4) + (0.3)(3) = 0.4 + 2.0 + 0.9 = 3.3\n",
    "$$\n",
    "\n",
    "For the y-coordinate:\n",
    "\n",
    "$$\n",
    "\\mu_y = w^1 x^1_y + w^2 x^2_y + w^3 x^3_y \\\\\n",
    "\\mu_y = (0.2)(3) + (0.5)(5) + (0.3)(4) = 0.6 + 2.5 + 1.2 = 4.3\n",
    "$$\n",
    "\n",
    "So, the estimated position of the robot is:\n",
    "\n",
    "$$\n",
    "\\mu = (\\mu_x, \\mu_y) = (3.3, 4.3)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Resampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the update step, the particles now have updated weights based on how well they match the robot's actual state. The next important step is resampling. Resampling is the process of replacing particles with low weights with new particles that are located in areas with higher probability (closer to where the robot likely is). \n",
    "\n",
    "#### Why do we need resampling ? \n",
    "\n",
    "Without resampling, particles would remain scattered across the map and wouldn't effectively use the new information from the sensor measurements. So, resampling is crucial because it helps the particles focus around the robot's true position. (Remember scan matching to remove the particles that are not well alligned with the scan )\n",
    "\n",
    "#### Here's how resampling works:\n",
    "\n",
    "*Selection of Particles:* We select a certain number of particles to carry over to the next iteration of Particle Filter Algorithm. Particles with higher weights are more likely to be chosen, meaning they're more likely to \"survive.\" Particles with low weights are less likely to be selected and are effectively discarded.\n",
    "\n",
    "*Generating New Particles:* We create new particles near the surviving high-weight particles. This means that more particles are placed in areas where the robot is more likely to be.\n",
    "\n",
    "This process results in particles clustering into groups or \"clouds.\" Each cloud represents a possible estimate of the robot's position. Because there may be several clusters, the filter is effectively considering multiple possible locations for the robot. This ability to represent multiple hypotheses is known as a multimodal distribution in statistics (as opposed to a single hypothesis, or unimodal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('resampling_particle_clouds.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image)\n",
    "plt.title('Clusters of particles formed after each Resampling step')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, the cluster with the highest combined weight will cover the area where the robot actually is. We use the average position (mean) and the spread (covariance) of that cluster to estimate the robot's position ( Just as we saw in Compute State Estimate Section)\n",
    "\n",
    "#### What is AMCL ?\n",
    "It is simply an extension of the standard particle filter known as the Adaptive Monte Carlo Localization (AMCL) algorithm. AMCL improves the resampling step by adjusting the number of particles dynamically:\n",
    "\n",
    "*When Uncertainty is High:* If the robot's position is very uncertain (many particles have low weights), AMCL increases the number of particles. This allows the algorithm to explore more possible positions.\n",
    "\n",
    "*When Confidence is High:* If the robot is confident about its position (particles have high weights), AMCL reduces the number of particles. This saves computational resources while maintaining accuracy.\n",
    "\n",
    "AMCL uses a method called KLD-sampling to decide how to adjust the number of particles based on the desired level of accuracy.\n",
    "\n",
    "#### What is Neff ? \n",
    "We donot have to perform resampling at every epoch that would be very computationally expensive. For instance, if you received no new sensor measurements than it doesnot make sensor to resample. So we can determine when to resample by using something called the effective N, which approximately measures the number of particles which meaningfully contribute to the probability distribution. If Neff falls below a certain threshold it is time to resample. \n",
    "\n",
    "Resampling is necessary to add diverstiy in the particles in our state space, we need diversity ! if Neff is low it means all the high weight is centered around a small set of particles. So we need to choose the threshold appropriately it could be Neff < N/2 which is the most common approach. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Parameters for Tuning the AMCL Node in ROS2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
